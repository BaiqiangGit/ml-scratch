{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdefcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85931c05",
   "metadata": {},
   "source": [
    "#### Tutorials:\n",
    "- YouTube video: https://youtu.be/wM-KP_wNAeY\n",
    "- Bilibili: https://www.bilibili.com/video/BV1P9tizcEKD/\n",
    "\n",
    "List of contents:\n",
    "- rope, gqa, rmsnorm, muon optimizer, swiglu, hf tokenizer and datasets, training, validation, amp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab27a9",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import math, random, os, pickle, warnings, time\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c263fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. utility functions\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Set all seeds to {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a69dec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. model config\n",
    "# smaller version of qwen3: 384 dimension, 6 layers, 8 heads\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    # Model Archtitecture\n",
    "    d_model: int = 384\n",
    "    n_heads: int = 8\n",
    "    n_layers: int = 6\n",
    "    d_ff: int = 1536\n",
    "    batch_size: int = 24\n",
    "    max_steps: int = 5000\n",
    "    \n",
    "    # Qwen specific parameters\n",
    "    n_kv_heads: int = 4\n",
    "    sliding_window_size: int = 4096\n",
    "    attention_bias: bool = False\n",
    "    rms_norm_eps: float = 1e-6\n",
    "    \n",
    "    # Training Parameters\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    muon_lr: float = 1e-2\n",
    "    \n",
    "    # Data parameters\n",
    "    max_seq_len: int = 8192\n",
    "    num_documents: int = 2000\n",
    "    max_tokens: int = 500000\n",
    "    \n",
    "    # Evaluation parameters\n",
    "    eval_every: int = 500\n",
    "    eval_steps: int = 100\n",
    "    \n",
    "    # Regularization \n",
    "    weight_decay: float = 0.1\n",
    "    dropout: float = 0.1\n",
    "    grad_clip: float = 1.0\n",
    "    \n",
    "    # Technical\n",
    "    use_amp: bool = True\n",
    "    vocab_size: Optional[int] = None  \n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.d_k = self.d_model // self.n_heads\n",
    "        assert self.d_model % self.n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "        assert self.n_heads % self.n_kv_heads == 0, \"n_heads must be divisible by n_kv_heads\" \n",
    "        self.n_kv_groups = self.n_heads // self.n_kv_heads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "408d2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Grouped Query Attention Module (GQA)\n",
    "# reduce memory usage by using fewer k,v heads\n",
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"Repeat the key and value heads n_rep times.\"\"\"   \n",
    "    \n",
    "    # early return if no repetition is needed\n",
    "    if n_rep == 1:\n",
    "        return hidden_states \n",
    "    \n",
    "    # extract dimensions from input tensor\n",
    "    batch, num_key_value_heads, seq_len, head_dim = hidden_states.shape\n",
    "    \n",
    "    # add new dimension at index 2 and expand\n",
    "    # shape change: \n",
    "    # (batch, num_key_value_heads, seq_len, head_dim) ->\n",
    "    # (batch, num_key_value_heads, 1, seq_len, head_dim)->\n",
    "    # (batch, num_key_value_heads, n_rep, seq_len, head_dim)\n",
    "    hidden_states = hidden_states.unsqueeze(2).expand(\n",
    "        batch, num_key_value_heads, n_rep, seq_len, head_dim)\n",
    "    \n",
    "    # Flatten the num_key_value_heads and n_rep dimensions to match num_attention_heads\n",
    "    # shape change:\n",
    "    # (batch, num_key_value_heads, n_rep, seq_len, head_dim) ->\n",
    "    # (batch, num_key_value_heads * n_rep, seq_len, head_dim)\n",
    "    # this effectively repeats each key/value head n_rep times\n",
    "    hidden_states = hidden_states.reshape(\n",
    "        batch, num_key_value_heads * n_rep, seq_len, head_dim)\n",
    "    return hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e244f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Code Exercises\n",
    "\n",
    "# ==============================================================\n",
    "# Exercise 1: Basic Tensor Creation & Shapes \n",
    "# ==============================================================\n",
    "print(\"=\" * 50)\n",
    "print(\"Exercize #1: Tensor Creation & Shapes Exercise\")\n",
    "x = torch.tensor([1,2,3])\n",
    "print(f\"1D tensor: {x}, shape: {x.shape} \")\n",
    "\n",
    "y = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(f\"2D tensor: {y}, shape: {y.shape} \")\n",
    "\n",
    "z = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "print(f\"3D tensor: {z}, shape: {z.shape} \")\n",
    "\n",
    "tensor_4d = torch.ones((2,3,4,5))\n",
    "# print(f\"4D tensor: {tensor_4d}, shape: {tensor_4d.shape} \")\n",
    "print(f\"4D tensor shape: {tensor_4d.shape} \")\n",
    "\n",
    "tensor_4d_copy = tensor_4d.clone()\n",
    "print(f\"Cloned 4D tensor shape: {tensor_4d_copy.shape} \")\n",
    "\n",
    "# ==============================================================\n",
    "# Exercise 2: Understanding None Indexing for dimension expansion\n",
    "# ==============================================================\n",
    "print(\"=\" * 50)\n",
    "print(\"Exercize #2: Understanding None Indexing for dimension expansion\")\n",
    "a = torch.Tensor([1, 2, 3, 4])\n",
    "print(f\"Original tensor a: {a}, shape: {a.shape}\")\n",
    "# add dimmension at different positions\n",
    "a_new_dim0 = a[None, :] # or a.unsqueeze(0) \n",
    "print(f\"Added new dimension at index 0: {a_new_dim0}, shape: {a_new_dim0.shape}\")\n",
    "a_new_dim1 = a[:, None] # or a.unsqueeze(1) \n",
    "print(f\"Added new dimension at index 1: {a_new_dim1}, shape: {a_new_dim1.shape}\")\n",
    "a_new_dim_end = a[..., None] # or a.unsqueeze(-1)\n",
    "print(f\"Added new dimension at end: {a_new_dim_end}, shape: {a_new_dim_end.shape}\")\n",
    "# multiple new dimensions\n",
    "a_multi_new_dims = a[None, :, None, None] # or a.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "print(f\"Added multiple new dimensions: {a_multi_new_dims}, shape: {a_multi_new_dims.shape}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# Exercise 3: Understanding Expand \n",
    "# ==============================================================\n",
    "print(\"=\" * 50)\n",
    "print(\"Exercize #3: Understanding Expand\")\n",
    "# expand() creates a new view with repeated elements without copying data\n",
    "b = torch.tensor([[1, 2, 3]])  # shape (1, 3)\n",
    "print(f\"Original tensor b shape: {b.shape}, b: {b}\")\n",
    "\n",
    "# Expand the first dimension from 1 to 4\n",
    "b_expanded = b.expand(4, 3)  # shape (4, 3)\n",
    "print(f\"Expanded tensor b shape: {b_expanded.shape}, \\nb_expanded: {b_expanded}\") \n",
    "\n",
    "# expand with -1: keep original size of that dimension\n",
    "c = torch.tensor([[1],[2],[3]])     # shape (3, 1)\n",
    "print(f\"Original tensor c shape: {c.shape}, c: {c}\")\n",
    "c_expanded = c.expand(-1, 4)  # shape (3, 4)\n",
    "print(f\"Expanded tensor c shape: {c_expanded.shape}, \\nc_expanded: {c_expanded}\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ac394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# expand in multiple dimensions\n",
    "d = torch.tensor([[1,2]]) # shape (1, 2)\n",
    "d_expanded = d.repeat(3, 2)  # shape (2, 3, 4)\n",
    "print(f\"Original tensor d shape: {d.shape}, d: {d}\")\n",
    "print(f\"Expanded tensor d shape: {d_expanded.shape}, \\nd_expanded: {d_expanded}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b15c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
